{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FitGenerator.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"zsNKA5a-reAB","colab_type":"code","outputId":"96317b49-e88a-4749-c9cf-875b91af3e0f","executionInfo":{"status":"ok","timestamp":1556176713624,"user_tz":240,"elapsed":1806,"user":{"displayName":"Vishal Shitole","photoUrl":"https://lh5.googleusercontent.com/-LW5ahZwF42I/AAAAAAAAAAI/AAAAAAAAABk/i29KOhv0UkY/s64/photo.jpg","userId":"03485937921662853560"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import glob\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras as keras\n","from keras.models import Sequential, Model\n","from keras.layers import Conv2D, Flatten, Dense, MaxPooling2D , Dropout,Conv3D, MaxPooling3D, Input, Deconv3D, BatchNormalization, Activation, Reshape\n","from keras.utils import to_categorical\n","from keras import optimizers\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","DATA_PATH = 'gdrive/My Drive/NN Capstone/Train_Input/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"RNxDBV0jrppW","colab_type":"code","outputId":"cefc53ca-4234-4db0-c0a8-c78f8272f62c","executionInfo":{"status":"ok","timestamp":1556176764921,"user_tz":240,"elapsed":1242,"user":{"displayName":"Vishal Shitole","photoUrl":"https://lh5.googleusercontent.com/-LW5ahZwF42I/AAAAAAAAAAI/AAAAAAAAABk/i29KOhv0UkY/s64/photo.jpg","userId":"03485937921662853560"}},"colab":{"base_uri":"https://localhost:8080/","height":663}},"cell_type":"code","source":["filters_in = [16]\n","kernel_size = [257]\n","strides = (2,2,2)\n","def encoder2D(kernel_size, strides):\n","    inputs = Input(shape=(512,1024,1))\n","\n","    g1 = Conv2D(filters=filters_in[0], kernel_size=kernel_size[0])(inputs)\n","    g1 = MaxPooling2D(pool_size=8)(g1)\n","    g1 = Activation(activation='relu')(g1)\n","\n","    g6 = Flatten()(g1)\n","     \n","    g8 = Dense(20,activation='sigmoid')(g6)\n","    g8 = Activation(activation='sigmoid')(g8) \n","    \n","    g9 = Reshape((1, 1,1,20), input_shape=(20,))(g8)\n","    \n","    g5 = Deconv3D(filters=1, kernel_size=32)(g9)\n","    g5 = BatchNormalization()(g5)\n","    g5 = Activation(activation='sigmoid')(g5) \n","    \n","    model = Model(inputs=inputs, outputs=g5)\n","    model.summary()\n","    model.compile(optimizer = 'adam', loss=['binary_crossentropy'], metrics=['mse'])\n","\n","    return model \n","encoder2D = encoder2D(kernel_size,strides)  \n","\n","\n","def create_model():\n","  model = Sequential()\n","  model.add(encoder2D)\n","  model.summary()\n","  model.compile(optimizer = 'adam', loss=['binary_crossentropy'], metrics=['mse'])\n","  return model\n","\n","model = create_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 512, 1024, 1)      0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 256, 768, 16)      1056800   \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 32, 96, 16)        0         \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 32, 96, 16)        0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 49152)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 20)                983060    \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 20)                0         \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 1, 1, 1, 20)       0         \n","_________________________________________________________________\n","conv3d_transpose_2 (Conv3DTr (None, 32, 32, 32, 1)     655361    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 32, 32, 32, 1)     4         \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 32, 32, 32, 1)     0         \n","=================================================================\n","Total params: 2,695,225\n","Trainable params: 2,695,223\n","Non-trainable params: 2\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","model_2 (Model)              (None, 32, 32, 32, 1)     2695225   \n","=================================================================\n","Total params: 2,695,225\n","Trainable params: 2,695,223\n","Non-trainable params: 2\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"cMNR66NIFR0B","colab_type":"code","colab":{}},"cell_type":"code","source":["# filters_in = [96, 256, 384,384,256]\n","# kernel_size = [4,8,16,16,8]\n","# strides = (2,2,2)\n","# def encoder2D(kernel_size, strides):\n","#     inputs = Input(shape=(512,1024,1))\n","\n","#     g1 = Conv2D(filters=filters_in[0], kernel_size=kernel_size[0])(inputs)\n","#     g1 = MaxPooling2D(pool_size=2)(g1)\n","#     g1 = Activation(activation='relu')(g1)\n","\n","#     g2 = Conv2D(filters=filters_in[1], kernel_size=kernel_size[1])(g1)\n","#     g2 = MaxPooling2D(pool_size=2)(g2)\n","#     g2 = Activation(activation='relu')(g2)\n","\n","#     g3 = Conv2D(filters=filters_in[2], kernel_size=kernel_size[2])(g2)\n","#     g3 = MaxPooling2D(pool_size=2)(g3)\n","#     g3 = Activation(activation='relu')(g3)\n","\n","#     g4 = Conv2D(filters=filters_in[3], kernel_size=kernel_size[3])(g3)\n","#     g4 = MaxPooling2D(pool_size=2)(g4)\n","#     g4 = Activation(activation='relu')(g4)\n","\n","#     g5 = Conv2D(filters=filters_in[4], kernel_size=kernel_size[4])(g4)\n","#     g5 = MaxPooling2D(pool_size=2)(g5)\n","#     g5 = Activation(activation='sigmoid')(g5) \n","    \n","#     g6 = Flatten()(g5)\n","    \n","#     g7 = Dense(400,activation='sigmoid')(g6)\n","#     g7 = Activation(activation='sigmoid')(g7) \n","    \n","#     g8 = Dense(200,activation='sigmoid')(g7)\n","#     g8 = Activation(activation='sigmoid')(g8) \n","    \n","#     g9 = Reshape((1, 1,1,200), input_shape=(200,))(g8)\n","    \n","    \n","#     model = Model(inputs=inputs, outputs=g9)\n","#     model.summary()\n","\n","#     return model \n","# encoder2D = encoder2D(kernel_size,strides)  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"8CVN4slyEVlg","colab_type":"code","colab":{}},"cell_type":"code","source":["# kernel_size = [4,8,32,100,100]\n","# strides = (2,2,2)\n","# def generator(kernel_size, strides):\n","#     inputs = Input(shape=(1, 1, 1, 200))\n","\n","#     g1 = Deconv3D(filters=512, kernel_size=kernel_size[0],strides=strides)(inputs)\n","#     g1 = BatchNormalization()(g1)\n","#     g1 = Activation(activation='relu')(g1)\n","\n","#     g2 = Deconv3D(filters=256, kernel_size=kernel_size[1],strides=strides)(g1)\n","#     g2 = BatchNormalization()(g2)\n","#     g2 = Activation(activation='relu')(g2)\n","\n","#     g3 = Deconv3D(filters=128, kernel_size=kernel_size[2],strides=strides)(g2)\n","#     g3 = BatchNormalization()(g3)\n","#     g3 = Activation(activation='relu')(g3)\n","\n","#     g4 = Deconv3D(filters=64, kernel_size=kernel_size[3])(g3)\n","#     g4 = BatchNormalization()(g4)\n","#     g4 = Activation(activation='relu')(g4)\n","\n","#     g5 = Deconv3D(filters=1, kernel_size=kernel_size[4])(g4)\n","#     g5 = BatchNormalization()(g5)\n","#     g5 = Activation(activation='sigmoid')(g5) \n","\n","#     model = Model(inputs=inputs, outputs=g5)\n","#     model.summary()\n","\n","#     return model \n","# generator = generator(kernel_size,strides)  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"hB4j0a2JFZ9t","colab_type":"code","colab":{}},"cell_type":"code","source":["# def create_model():\n","#   model = Sequential()\n","#   model.add(encoder2D)\n","#   model.add(generator)\n","#   model.summary()\n","#   model.compile(optimizer = 'adam', loss=['binary_crossentropy'], metrics=['mse'])\n","#   return model\n","\n","# model = create_model()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HV70aUvqr5V1","colab_type":"code","colab":{}},"cell_type":"code","source":["# def tr_generator():\n","#   print(\"generator Initiated\")\n","#   idx = 0;\n","#   while(True):\n","#     for specimen in glob.glob(DATA_PATH + 'species_1/specimen_*/'):\n","#       head, specimen_name = os.path.split(specimen)\n","#       head, specimen_name = os.path.split(head)\n","#       for view in glob.iglob(specimen + 'View_*_n*'):\n","#         #specimen_view_list.append(view)\n","#         head, normal_img = os.path.split(view)\n","#         depth_img = normal_img.replace('_n', '_d') \n","#         normal = np.load(specimen + normal_img)\n","#         depth = np.load(specimen + depth_img)\n","#         input_data = np.concatenate((normal,depth),axis=1)\n","#         input_data = input_data.reshape(1,512,1024,1)\n","#         label = np.load(specimen + specimen_name + '.npy')\n","#         label = label.reshape(1,256,256,256,1)\n","#         print(head)\n","#         print(input_data.shape, label.shape)\n","#         print(depth_img, normal_img)\n","#         idx = idx + 1\n","#         yield input_data,label\n","    \n","   \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W-5H8PjPU8y5","colab_type":"code","colab":{}},"cell_type":"code","source":["def tr_generator(idx=0):\n","  print(\"generator Initiated\")\n","  idx = 0;\n","  while(True):\n","      for specimen in glob.glob(DATA_PATH + 'species_1/specimen_00/View_0*_n*'):\n","        head1, tail1 = os.path.split(specimen)\n","        head, specimen_name = os.path.split(head1)\n","        print(head1,head,tail1)\n","        head, normal_img = os.path.split(specimen)\n","        depth_img = normal_img.replace('_n', '_d') \n","        normal = np.load(head1 + '/' + normal_img)\n","        depth = np.load(head1 + '/' + depth_img)\n","        input_data = np.concatenate((normal,depth),axis=1)\n","        input_data = input_data.reshape(1,512,1024,1)\n","        label = np.load(head1 + '/' + specimen_name + '.npy')\n","        label = label.reshape(512,32,32,32,1)\n","        label = label[0].reshape(1,32,32,32,1)\n","        print(head)\n","        print(input_data.shape, label.shape)\n","        print(depth_img, normal_img)\n","        idx = idx + 1\n","        input_data,label\n","        yield (input_data, label)\n","    \n","#x_tr, y_tr = tr_generator()\n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"oUcfZcSv75Gp","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KIXaetmxN7Af","colab_type":"code","colab":{}},"cell_type":"code","source":["{# x1 = []\n","\n","# for specimen in glob.glob(DATA_PATH + 'species_1/specimen_00/'):\n","#     head, specimen_name = os.path.split(specimen)\n","#     head, specimen_name = os.path.split(head)\n","#     for view in glob.iglob(specimen + 'View_*_n*'):\n","#        for i in range(1):\n","#         head, normal_img = os.path.split(view)\n","#         depth_img = normal_img.replace('_n', '_d')     \n","#         in1 = (normal_img, depth_img, specimen_name )\n","#         x1.append(in1)\n","# print(x1)\n","# print(x1[0][0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2pSYrZh23K-T","colab_type":"code","outputId":"54e70797-4365-40e7-c230-352f694242e6","executionInfo":{"status":"ok","timestamp":1556166946832,"user_tz":240,"elapsed":501,"user":{"displayName":"Vishal Shitole","photoUrl":"https://lh5.googleusercontent.com/-LW5ahZwF42I/AAAAAAAAAAI/AAAAAAAAABk/i29KOhv0UkY/s64/photo.jpg","userId":"03485937921662853560"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["x1 = []\n","\n","for specimen in glob.glob(DATA_PATH + 'species_1/specimen_00/View_0^(1[0-5])$_n*'):\n","        head1, tail1 = os.path.split(specimen)\n","        head, specimen_name = os.path.split(head1)\n","        print(head1,head,tail1)\n","        head, normal_img = os.path.split(specimen)\n","        depth_img = normal_img.replace('_n', '_d') \n","      #  normal = np.load(head1 + '/' + normal_img)\n","      #  depth = np.load(head1 + '/' + depth_img)\n","      #  input_data = np.concatenate((normal,depth),axis=1)\n","      #  input_data = input_data.reshape(1,512,1024,1)\n","      #  label = np.load(head1 + '/' + specimen_name + '.npy')\n","      #  label = label.reshape(1,256,256,256,1)\n","        print(head)\n","    #    print(input_data.shape, label.shape)\n","        print(depth_img, normal_img)\n","   #     idx = idx + 1\n","      #  input_data,label\n","      #  in1 = (input_data, label) \n","      #  x1.append(in1)\n","print(x1)\n","# print(x1[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[]\n"],"name":"stdout"}]},{"metadata":{"id":"l-DE070OMhqm","colab_type":"code","colab":{}},"cell_type":"code","source":["# file_path = DATA_PATH + 'species_1/specimen_00/'\n","# def tr_generator(file_path):\n","#   idx=0\n","#   while idx==3:\n","#     #for i1,i2,y in x1:\n","#       idx=idx+1\n","#       i1='View_03_n.npy'\n","#       i2='View_03_d.npy'\n","#       y='specimen_00'\n","#       print(i1,i2,y)\n","#       n = np.load(file_path+i1)\n","#       d = np.load(file_path+i2)\n","#       label = np.load(file_path+y+'.npy')\n","#       input_data = np.concatenate((n,d),axis=1)\n","#       input_data = input_data.reshape(1,512,1024,1)\n","#       label = label.reshape(1,256,256,256,1)\n","#       yield (input_data,label)\n","    \n","\n","  \n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"tGwcYBUHQdQi","colab_type":"code","outputId":"9f8fb1fd-660e-47ab-d05d-37631fbf94ef","colab":{"base_uri":"https://localhost:8080/","height":938}},"cell_type":"code","source":["model.fit_generator(tr_generator(),verbose=2,steps_per_epoch=1,epochs =1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/1\n","generator Initiated\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_03_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_03_d.npy View_03_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_01_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_01_d.npy View_01_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_00_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_00_d.npy View_00_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_04_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_04_d.npy View_04_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_06_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_06_d.npy View_06_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_05_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_05_d.npy View_05_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_08_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_08_d.npy View_08_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_07_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_07_d.npy View_07_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_03_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_03_d.npy View_03_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_01_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_01_d.npy View_01_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_00_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_00_d.npy View_00_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00 gdrive/My Drive/NN Capstone/Train_Input/species_1 View_04_n.npy\n","gdrive/My Drive/NN Capstone/Train_Input/species_1/specimen_00\n","(1, 512, 1024, 1) (1, 32, 32, 32, 1)\n","View_04_d.npy View_04_n.npy\n"],"name":"stdout"}]},{"metadata":{"id":"eW-9denJFbEN","colab_type":"code","colab":{}},"cell_type":"code","source":["# history = model.fit_generator(generator=tr_generator,   \n","#      #                         samples_per_epoch=1, nb_epoch=1,verbose=1)\n","#                      steps_per_epoch=10,\n","#                      epochs=2,\n","#                      verbose=1,                \n","#                      use_multiprocessing=True)\n","# #                     workers=5,\n","# #                     max_queue_size=1) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"nNrm5AUnKEd_","colab_type":"code","outputId":"dc0581e6-d09d-405c-b81f-93dfcb2875c8","executionInfo":{"status":"ok","timestamp":1556157539056,"user_tz":240,"elapsed":319,"user":{"displayName":"Vishal Shitole","photoUrl":"https://lh5.googleusercontent.com/-LW5ahZwF42I/AAAAAAAAAAI/AAAAAAAAABk/i29KOhv0UkY/s64/photo.jpg","userId":"03485937921662853560"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["all_files_loc = DATA_PATH + 'species_1/specimen_22/'\n","all_files = os.listdir(all_files_loc)\n","print(all_files)\n","image_label_map = {\n","         \"View_{0:02}_n.npy\".format(i+1): \"specimen_22.npy\".format(i+1)\n","        for i in range(int(len(all_files)/2))}\n","partition = [item for item in all_files if \"View_\" and \"_n\" in item]\n","\n","print(image_label_map)\n","print(partition)\n","\n","class DataGenerator(keras.utils.Sequence):\n","\n","    def __init__(self, file_list):\n","        \"\"\"Constructor can be expanded,\n","           with batch size, dimentation etc.\n","        \"\"\"\n","        self.file_list = file_list\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","      'Take all batches in each iteration'\n","      return int(len(self.file_list))\n","\n","    def __getitem__(self, index):\n","      'Get next batch'\n","      # Generate indexes of the batch\n","      indexes = self.indexes[index:(index+1)]\n","\n","      # single file\n","      file_list_temp = [self.file_list[k] for k in indexes]\n","\n","      # Set of X_train and y_train\n","      X, y = self.__data_generation(file_list_temp)\n","\n","      return X, y\n","\n","    def on_epoch_end(self):\n","      'Updates indexes after each epoch'\n","      self.indexes = np.arange(len(self.file_list))\n","\n","    def __data_generation(self, file_list_temp):\n","      'Generates data containing batch_size samples'\n","      data_loc = DATA_PATH + 'species_1/specimen_22/'\n","      # Generate data\n","      for ID in file_list_temp:\n","       #   print(data_loc)\n","       #   print(image_label_map.get(ID))\n","       #   print(ID)\n","          n_file_path = os.path.join(data_loc, ID)\n","          ID2 = ID.replace('_n', '_d')\n","          d_file_path = os.path.join(data_loc, ID2)\n","        #  print(d_file_path)\n","          y_file_path = os.path.join(data_loc, image_label_map.get(ID))\n","          \n","          # Store sample\n","          N = np.load(n_file_path)\n","          D = np.load(d_file_path)\n","          X = np.concatenate((N,D),axis=1)\n","          X = X.reshape(1,512,1024,1)\n","          \n","          # Store class\n","          Y = np.load(y_file_path)\n","          Y = Y.reshape(1,256*256*256)\n","\n","      return X, Y\n","\n","# # ====================\n","# # train set\n","# # ====================\n","# #all_files_loc = DATA_PATH + 'species_1/specimen_00/'\n","# all_files = os.listdir(DATA_PATH)\n","\n","# training_generator = DataGenerator(partition)\n","# validation_generator = ValDataGenerator(val_partition) # work same as training generator\n","\n","# hst = model.fit_generator(generator=training_generator, \n","#                            epochs=200, \n","#                            validation_data=validation_generator,\n","#                            use_multiprocessing=True,\n","#                            max_queue_size=32) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["['specimen_22.binvox', 'specimen_22.npy', 'View_00_n.npy', 'View_00_d.npy', 'View_03_n.npy', 'View_03_d.npy', 'View_01_n.npy', 'View_01_d.npy', 'View_04_n.npy', 'View_04_d.npy', 'View_07_n.npy', 'View_07_d.npy', 'View_08_n.npy', 'View_08_d.npy', 'View_05_n.npy', 'View_05_d.npy', 'View_06_n.npy', 'View_06_d.npy', 'View_13_n.npy', 'View_13_d.npy', 'View_12_n.npy', 'View_12_d.npy', 'View_11_n.npy', 'View_11_d.npy', 'View_15_n.npy', 'View_15_d.npy', 'View_18_n.npy', 'View_18_d.npy', 'View_19_n.npy', 'View_19_d.npy', 'View_17_n.npy', 'View_17_d.npy', 'View_20_n.npy', 'View_20_d.npy', 'View_23_n.npy', 'View_23_d.npy', 'View_22_n.npy', 'View_22_d.npy', 'View_26_n.npy', 'View_26_d.npy', 'View_28_n.npy', 'View_28_d.npy', 'View_29_n.npy', 'View_29_d.npy', 'View_25_n.npy', 'View_25_d.npy', 'View_27_n.npy', 'View_27_d.npy', 'View_30_n.npy', 'View_30_d.npy', 'View_34_n.npy', 'View_34_d.npy', 'View_31_n.npy', 'View_31_d.npy', 'View_33_n.npy', 'View_33_d.npy', 'View_32_n.npy', 'View_32_d.npy', 'View_39_n.npy', 'View_39_d.npy', 'View_38_n.npy', 'View_38_d.npy', 'View_35_n.npy', 'View_35_d.npy', 'View_37_n.npy', 'View_37_d.npy', 'View_36_n.npy', 'View_36_d.npy', 'View_40_n.npy', 'View_40_d.npy', 'View_41_n.npy', 'View_41_d.npy', 'View_42_n.npy', 'View_42_d.npy', 'View_44_n.npy', 'View_44_d.npy', 'View_49_n.npy', 'View_49_d.npy', 'View_46_n.npy', 'View_46_d.npy', 'View_48_n.npy', 'View_48_d.npy']\n","{'View_01_n.npy': 'specimen_22.npy', 'View_02_n.npy': 'specimen_22.npy', 'View_03_n.npy': 'specimen_22.npy', 'View_04_n.npy': 'specimen_22.npy', 'View_05_n.npy': 'specimen_22.npy', 'View_06_n.npy': 'specimen_22.npy', 'View_07_n.npy': 'specimen_22.npy', 'View_08_n.npy': 'specimen_22.npy', 'View_09_n.npy': 'specimen_22.npy', 'View_10_n.npy': 'specimen_22.npy', 'View_11_n.npy': 'specimen_22.npy', 'View_12_n.npy': 'specimen_22.npy', 'View_13_n.npy': 'specimen_22.npy', 'View_14_n.npy': 'specimen_22.npy', 'View_15_n.npy': 'specimen_22.npy', 'View_16_n.npy': 'specimen_22.npy', 'View_17_n.npy': 'specimen_22.npy', 'View_18_n.npy': 'specimen_22.npy', 'View_19_n.npy': 'specimen_22.npy', 'View_20_n.npy': 'specimen_22.npy', 'View_21_n.npy': 'specimen_22.npy', 'View_22_n.npy': 'specimen_22.npy', 'View_23_n.npy': 'specimen_22.npy', 'View_24_n.npy': 'specimen_22.npy', 'View_25_n.npy': 'specimen_22.npy', 'View_26_n.npy': 'specimen_22.npy', 'View_27_n.npy': 'specimen_22.npy', 'View_28_n.npy': 'specimen_22.npy', 'View_29_n.npy': 'specimen_22.npy', 'View_30_n.npy': 'specimen_22.npy', 'View_31_n.npy': 'specimen_22.npy', 'View_32_n.npy': 'specimen_22.npy', 'View_33_n.npy': 'specimen_22.npy', 'View_34_n.npy': 'specimen_22.npy', 'View_35_n.npy': 'specimen_22.npy', 'View_36_n.npy': 'specimen_22.npy', 'View_37_n.npy': 'specimen_22.npy', 'View_38_n.npy': 'specimen_22.npy', 'View_39_n.npy': 'specimen_22.npy', 'View_40_n.npy': 'specimen_22.npy', 'View_41_n.npy': 'specimen_22.npy'}\n","['View_00_n.npy', 'View_03_n.npy', 'View_01_n.npy', 'View_04_n.npy', 'View_07_n.npy', 'View_08_n.npy', 'View_05_n.npy', 'View_06_n.npy', 'View_13_n.npy', 'View_12_n.npy', 'View_11_n.npy', 'View_15_n.npy', 'View_18_n.npy', 'View_19_n.npy', 'View_17_n.npy', 'View_20_n.npy', 'View_23_n.npy', 'View_22_n.npy', 'View_26_n.npy', 'View_28_n.npy', 'View_29_n.npy', 'View_25_n.npy', 'View_27_n.npy', 'View_30_n.npy', 'View_34_n.npy', 'View_31_n.npy', 'View_33_n.npy', 'View_32_n.npy', 'View_39_n.npy', 'View_38_n.npy', 'View_35_n.npy', 'View_37_n.npy', 'View_36_n.npy', 'View_40_n.npy', 'View_41_n.npy', 'View_42_n.npy', 'View_44_n.npy', 'View_49_n.npy', 'View_46_n.npy', 'View_48_n.npy']\n"],"name":"stdout"}]},{"metadata":{"id":"nm7x-n4SeZoE","colab_type":"code","outputId":"6cf6eadc-777c-4b72-d545-74459222ae2a","colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["training_generator = DataGenerator(partition)\n","X,Y = training_generator.__getitem__(3)\n","#model.fit_generator(training_generator,verbose=2,steps_per_epoch=1,epochs =1,use_multiprocessing=True, workers=6)\n","model.fit(X,Y,verbose=0,batch_size=1,epochs =1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"}]}]}